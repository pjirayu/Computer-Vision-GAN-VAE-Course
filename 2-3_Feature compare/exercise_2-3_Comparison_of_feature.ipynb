{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_3_5_Comparison_of_Latent_Vector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhRIufI0Xhn1"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch.nn as nn"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hYzFka9Xj87"
      },
      "source": [
        "def preprocess_image(cv2im, resize_im=True):\n",
        "\n",
        "    # Resize image\n",
        "    if resize_im:\n",
        "        cv2im = cv2.resize(cv2im, (224, 224))\n",
        "    im_as_arr = np.float32(cv2im)\n",
        "    im_as_arr = np.ascontiguousarray(im_as_arr[..., ::-1])\n",
        "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
        "    # Normalize the channels\n",
        "    for channel, _ in enumerate(im_as_arr):\n",
        "        im_as_arr[channel] /= 255\n",
        "    # Convert to float tensor\n",
        "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
        "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
        "    im_as_ten.unsqueeze_(0)\n",
        "    # Convert to Pytorch variable\n",
        "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
        "    return im_as_var"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkptXxluXmbL"
      },
      "source": [
        "class FeatureVisualization():\n",
        "    def __init__(self,img_path,selected_layer):\n",
        "        self.img_path=img_path\n",
        "        self.selected_layer=selected_layer\n",
        "        # Load pretrained model\n",
        "        \n",
        "        self.pretrained_model = models.vgg16(pretrained=True).features\n",
        "        self.pretrained_model.eval()\n",
        "        # self.pretrained_model2 = models.vgg16(pretrained=True)\n",
        "        self.pretrained_model2 = models.resnet50(pretrained=True)\n",
        "        self.pretrained_model2.eval()\n",
        "    def process_image(self):\n",
        "        img=cv2.imread(self.img_path)\n",
        "        img=preprocess_image(img)\n",
        "        return img\n",
        "\n",
        "    def get_feature(self):\n",
        "        # Image  preprocessing\n",
        "        input=self.process_image()\n",
        "        #print(\"input.shape:{}\".format(input.shape))\n",
        "        x=input\n",
        "        for index,layer in enumerate(self.pretrained_model):\n",
        "            x=layer(x)\n",
        "            #print(\"x:{}\".format(x.shape))\n",
        "            if (index == self.selected_layer):\n",
        "                return x\n",
        "\n",
        "    def get_single_feature(self):\n",
        "        # Get the feature map\n",
        "\n",
        "        features=self.get_feature()\n",
        "        #print(features.shape)\n",
        "        feature=features[:,0,:,:]\n",
        "        feature=feature.view(feature.shape[1],feature.shape[2])\n",
        "\n",
        "        #print(\"feature\")\n",
        "        #print(feature.shape)\n",
        "        return feature\n",
        "\n",
        "    def get_multi_feature(self):\n",
        "        # Get the feature map\n",
        "        features=self.get_feature()\n",
        "        #print(features.shape)\n",
        "        result_path = './feat_first' + str(self.selected_layer)\n",
        "\n",
        "        if not os.path.exists(result_path):\n",
        "            os.makedirs(result_path)\n",
        "        print(\"On layer:{}, We can get the {} feature maps\".format(self.selected_layer,features.shape[1]))    \n",
        "        #print(features.shape[1])\n",
        "        for i in range(features.shape[1]):\n",
        "            feature=features[:,i,:,:]\n",
        "            feature=feature.view(feature.shape[1],feature.shape[2])\n",
        "            feature = feature.data.numpy()\n",
        "            feature = 1.0 / (1 + np.exp(-1 * feature))\n",
        "            feature = np.round(feature * 255)\n",
        "            save_name = result_path + '/' + str(i) + '.jpg'\n",
        "            cv2.imwrite(save_name, feature)\n",
        "    def get_multi_feature1(self):\n",
        "        # Get the feature map\n",
        "        features=self.get_feature()\n",
        "        #print(features.shape)\n",
        "        result_path = './feat_second' + str(self.selected_layer)\n",
        "\n",
        "        if not os.path.exists(result_path):\n",
        "            os.makedirs(result_path)\n",
        "        print(\"On layer:{}, We can get the {} feature maps\".format(self.selected_layer,features.shape[1]))    \n",
        "        #print(features.shape[1])\n",
        "        for i in range(features.shape[1]):\n",
        "            feature=features[:,i,:,:]\n",
        "            feature=feature.view(feature.shape[1],feature.shape[2])\n",
        "            feature = feature.data.numpy()\n",
        "            feature = 1.0 / (1 + np.exp(-1 * feature))\n",
        "            feature = np.round(feature * 255)\n",
        "            save_name = result_path + '/' + str(i) + '.jpg'\n",
        "            cv2.imwrite(save_name, feature)\n",
        "\n",
        "    def save_feature_to_img(self):\n",
        "        #to numpy\n",
        "        feature=self.get_single_feature()\n",
        "        self.get_multi_feature()\n",
        "        feature=feature.data.numpy()\n",
        "\n",
        "        #use sigmod to [0,1]\n",
        "        # print(feature[0])\n",
        "        feature= 1.0/(1+np.exp(-1*feature))\n",
        "\n",
        "        # to [0,255]\n",
        "        feature=np.round(feature*255)\n",
        "        #print(self.selected_layer)\n",
        "        save_name = './feat_first' + str(self.selected_layer) + '.jpg'\n",
        "        cv2.imwrite(save_name, feature)\n",
        "    def save_feature_to_img1(self):\n",
        "        #to numpy\n",
        "        feature=self.get_single_feature()\n",
        "        self.get_multi_feature1()\n",
        "        feature=feature.data.numpy()\n",
        "\n",
        "        #use sigmod to [0,1]\n",
        "        # print(feature[0])\n",
        "        feature= 1.0/(1+np.exp(-1*feature))\n",
        "\n",
        "        # to [0,255]\n",
        "        feature=np.round(feature*255)\n",
        "        #print(self.selected_layer)\n",
        "        save_name = './feat_second' + str(self.selected_layer) + '.jpg'\n",
        "        cv2.imwrite(save_name, feature)\n",
        "    def plot_probablity(self,outputs):\n",
        "\n",
        "        outputs = outputs.data.numpy()\n",
        "        outputs = np.ndarray.tolist(outputs)\n",
        "\n",
        "        x = range(0, 1000)\n",
        "        plt.bar(x, outputs[0])\n",
        "        plt.xlabel(\"Class\")\n",
        "        plt.ylabel(\"Probablity\")\n",
        "        plt.title(\"Image classifier\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        input=self.process_image()\n",
        "        outputs = self.pretrained_model2(input)\n",
        "\n",
        "        s = torch.nn.Softmax(dim=1)\n",
        "        result = s(outputs)\n",
        "        self.plot_probablity(result)\n",
        "\n",
        "        prob, predicted = result.sort(1,descending=True)\n",
        "        prob = prob.data.numpy()\n",
        "\n",
        "        predicted = predicted.data.numpy()\n",
        "        \n",
        "        print(\"Probablity TOP-3:\\n\")\n",
        "        print(\"\")\n",
        "        for i in range(3):\n",
        "            \n",
        "            print(\"TOP_\"+str(i+1))\n",
        "            print(\"Probablity:{}\".format(prob[0][i]))\n",
        "            print(\"Predicted:{}\\n\".format(c[int(predicted[0][i])]))\n",
        "        return outputs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGgajl_4XogN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f445827-d05e-4b8c-b92a-59d6faee7df1"
      },
      "source": [
        "if __name__=='__main__':\n",
        "    # get class\n",
        "    c = {}\n",
        "    with open(\"imagenet1000_clsidx_to_labels.txt\") as f:\n",
        "        for line in f:\n",
        "            (key, val) = line.split(\":\")\n",
        "            c[int(key)] = val.split(\",\")[0]\n",
        "    # Define image path and select the layer\n",
        "    myClass=FeatureVisualization('./dog6.jpg',12)\n",
        "    Compare=FeatureVisualization('./dog9.jpg',12)    \n",
        "    print(myClass.pretrained_model2)\n",
        "\n",
        "    myClass.save_feature_to_img()\n",
        "    Compare.save_feature_to_img1()\n",
        "    print(\"The first picture classification predict:\")\n",
        "    myClass_vector = myClass.predict()\n",
        "    print(\"The second picture classification predict:\")\n",
        "    Compare_vector = Compare.predict()\n",
        "    #Define cosine similarity\n",
        "    cos= nn.CosineSimilarity(dim=1)\n",
        "    #Define Euclidean distance\n",
        "    euclidean_dist = torch.dist(myClass_vector,Compare_vector,p=2)\n",
        "    cosine_dist = 1-cos(myClass_vector,Compare_vector)\n",
        "    print(\"Verification:\")\n",
        "    if cosine_dist < 0.6:\n",
        "        print(\"They are the same!\")\n",
        "        print(\"Their cosine_distance:{}\".format(cosine_dist))\n",
        "    else:\n",
        "        print(\"They are not the same!\")\n",
        "        print(\"Their cosine_distance:{}\".format(cosine_dist))\n",
        "       \n",
        "    print(\"Their euclidean_dist:{}\".format(euclidean_dist))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n",
            "On layer:12, We can get the 256 feature maps\n",
            "On layer:12, We can get the 256 feature maps\n",
            "The first picture classification predict:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Probablity TOP-3:\n",
            "\n",
            "\n",
            "TOP_1\n",
            "Probablity:0.4704395532608032\n",
            "Predicted: 'brown bear\n",
            "\n",
            "TOP_2\n",
            "Probablity:0.13553866744041443\n",
            "Predicted: 'mongoose'\n",
            "\n",
            "TOP_3\n",
            "Probablity:0.07361361384391785\n",
            "Predicted: 'ice bear\n",
            "\n",
            "The second picture classification predict:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Probablity TOP-3:\n",
            "\n",
            "\n",
            "TOP_1\n",
            "Probablity:0.8545098900794983\n",
            "Predicted: 'Labrador retriever'\n",
            "\n",
            "TOP_2\n",
            "Probablity:0.04048657417297363\n",
            "Predicted: 'golden retriever'\n",
            "\n",
            "TOP_3\n",
            "Probablity:0.026116173714399338\n",
            "Predicted: 'kuvasz'\n",
            "\n",
            "Verification:\n",
            "They are not the same!\n",
            "Their cosine_distance:tensor([0.9033], grad_fn=<RsubBackward1>)\n",
            "Their euclidean_dist:90.57671356201172\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}