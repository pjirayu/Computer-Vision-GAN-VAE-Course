{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exercise_5.1_CGAN_D10907801.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4CPzCxWXTG-0"},"source":["# In Class Exercise 8.1\n","\n","We first import our framework. Since we are already familiar with pytorch, we will use the torch library. This will make it easy for us since we can use functions and classes other coders have already implemented."]},{"cell_type":"code","metadata":{"id":"DxzQRNHPTHaL","executionInfo":{"status":"ok","timestamp":1621319281860,"user_tz":-480,"elapsed":671,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}}},"source":["import os, time\n","import matplotlib.pyplot as plt\n","import itertools\n","import pickle\n","import imageio\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","from torchvision.utils import save_image, make_grid\n","import numpy as np\n","import cv2\n","\n","# !pip install torchsummary\n","from torchsummary import summary"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ssfLeHSGNtb"},"source":["### Define the hyper-parameter and load the training dataset\n","\n","hyperparameters we define in here\n","\n","- img_size\n","- batch_size (how big is one batch. This splits our dataset into equal pieces that we will feed into our neural network)\n","- train_epoch (How long will we train)\n","- learning rate\n","- dataset we will use\n"]},{"cell_type":"code","metadata":{"id":"qPqstJ2GIWWH","executionInfo":{"status":"ok","timestamp":1621318853133,"user_tz":-480,"elapsed":762,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}}},"source":["# training parameters\n","batch_size = 128\n","lr = 0.0001\n","train_epoch = 20\n","\n","img_size = 64"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"imhsH0AnHQKN","executionInfo":{"status":"ok","timestamp":1621318847574,"user_tz":-480,"elapsed":650,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}}},"source":["# data_loader\n","\n","transform = transforms.Compose([\n","        transforms.Resize(img_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5], [0.5])\n","])\n","\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('data', train=True, download=True, transform=transform),\n","    batch_size=batch_size, shuffle=True)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8KWyhskHCls"},"source":["In here we are defining some functions that we will use later. Functions are very useful and you should write your functions whenever your code benefits from it. You should always declare your functions first in your script.\n","\n","- normal_init (we will use this function to initialize our weights)\n","- show_result (outputs the images to a .png image)\n","- show the loss curve"]},{"cell_type":"code","metadata":{"id":"FgtuRMcQTOZy","executionInfo":{"status":"ok","timestamp":1621318860690,"user_tz":-480,"elapsed":971,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}}},"source":["def normal_init(m, mean, std):\n","    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n","        m.weight.data.normal_(mean, std)\n","        m.bias.data.zero_()\n","\n","# fixed noise & label\n","temp_z_ = torch.randn(10, 100)\n","fixed_z_ = temp_z_\n","fixed_y_ = torch.zeros(10, 1)\n","for i in range(9):\n","    fixed_z_ = torch.cat([fixed_z_, temp_z_], 0)\n","    temp = torch.ones(10, 1) + i\n","    fixed_y_ = torch.cat([fixed_y_, temp], 0)\n","\n","fixed_z_ = fixed_z_.view(-1, 100, 1, 1)\n","fixed_y_label_ = torch.zeros(100, 10)\n","fixed_y_label_.scatter_(1, fixed_y_.type(torch.LongTensor), 1)\n","fixed_y_label_ = fixed_y_label_.view(-1, 10, 1, 1)\n","fixed_z_, fixed_y_label_ = Variable(fixed_z_.cuda()), Variable(fixed_y_label_.cuda())\n","\n","def show_result(num_epoch, show = False, save = False, path = 'result.png'):\n","\n","    G.eval()\n","    with torch.no_grad():\n","      test_images = G(fixed_z_, fixed_y_label_)\n","    G.train()\n","\n","    size_figure_grid = 10\n","    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(5, 5))\n","    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n","        ax[i, j].get_xaxis().set_visible(False)\n","        ax[i, j].get_yaxis().set_visible(False)\n","\n","    for k in range(10*10):\n","        i = k // 10\n","        j = k % 10\n","        ax[i, j].cla()\n","        ax[i, j].imshow(test_images[k, 0].cpu().data.numpy(), cmap='gray')\n","\n","    label = 'Epoch {0}'.format(num_epoch)\n","    fig.text(0.5, 0.04, label, ha='center')\n","    plt.savefig(path)\n","\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close()\n","\n","def show_train_hist(hist, show = True, save = False, path = 'Train_hist.png'):\n","    x = range(len(hist['D_losses']))\n","\n","    y1 = hist['D_losses']\n","    y2 = hist['G_losses']\n","\n","    plt.plot(x, y1, label='D_loss')\n","    plt.plot(x, y2, label='G_loss')\n","\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","\n","    plt.legend(loc=4)\n","    plt.grid(True)\n","    plt.tight_layout()\n","\n","    if save:\n","        plt.savefig(path)\n","\n","    if show:\n","        plt.show()\n","    else:\n","        plt.close()\n"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E68q6m61HrmB"},"source":["# Define the generator and discriminator"]},{"cell_type":"code","metadata":{"id":"Flrj573EHmF3","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"error","timestamp":1621319675133,"user_tz":-480,"elapsed":797,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}},"outputId":"031c320d-c38c-4b24-d338-6eb490bf0527"},"source":["# G(z)\n","class generator(nn.Module):\n","    # initializers\n","    def __init__(self, d=128):\n","        super(generator, self).__init__()\n","        self.deconv1_1 = nn.ConvTranspose2d(100, d*2, 4, 1, 0)\n","        self.deconv1_1_bn = nn.BatchNorm2d(d*2)\n","        self.deconv1_2 = nn.ConvTranspose2d(10, d*2, 4, 1, 0)\n","        self.deconv1_2_bn = nn.BatchNorm2d(d*2)\n","        self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n","        self.deconv2_bn = nn.BatchNorm2d(d*2)\n","        self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n","        self.deconv3_bn = nn.BatchNorm2d(d)\n","        self.deconv4 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n","\n","    # weight_init\n","    def weight_init(self, mean, std):\n","        for m in self._modules:\n","            normal_init(self._modules[m], mean, std)\n","\n","    # forward method\n","    def forward(self, input, label):\n","        x = F.relu(self.deconv1_1_bn(self.deconv1_1(input)))\n","        y = F.relu(self.deconv1_2_bn(self.deconv1_2(label)))\n","        x = torch.cat([x, y], 1)\n","        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n","        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n","        x = F.tanh(self.deconv4(x))\n","\n","        return x\n","\n","class discriminator(nn.Module):\n","    # initializers\n","    def __init__(self, d=128):\n","        super(discriminator, self).__init__()\n","        self.conv1_1 = nn.Conv2d(1, d//2, 4, 2, 1)\n","        self.conv1_2 = nn.Conv2d(10, d//2, 4, 2, 1)\n","        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n","        self.conv2_bn = nn.BatchNorm2d(d*2)\n","        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n","        self.conv3_bn = nn.BatchNorm2d(d*4)\n","        self.conv4 = nn.Conv2d(d * 4, 1, 4, 1, 0)\n","\n","    # weight_init\n","    def weight_init(self, mean, std):\n","        for m in self._modules:\n","            normal_init(self._modules[m], mean, std)\n","\n","    # forward method\n","    def forward(self, input, label):\n","        x = F.leaky_relu(self.conv1_1(input), 0.2)\n","        y = F.leaky_relu(self.conv1_2(label), 0.2)\n","        x = torch.cat([x, y], 1)\n","        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n","        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n","        x = F.sigmoid(self.conv4(x))\n","\n","        return x\n","\n","summary(generator,input_size=(100,1,1,1))"],"execution_count":32,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-4f425950fdc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# register hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: apply() missing 1 required positional argument: 'fn'"]}]},{"cell_type":"markdown","metadata":{"id":"T25Ec8pCH5zP"},"source":["### Create an instance of our generator and discriminator"]},{"cell_type":"code","metadata":{"id":"GM0DbtdtTTim","executionInfo":{"status":"ok","timestamp":1621318868064,"user_tz":-480,"elapsed":1024,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}}},"source":["# network\n","G = generator(256)\n","D = discriminator(256)\n","\n","G.weight_init(mean=0.0, std=0.02)\n","D.weight_init(mean=0.0, std=0.02)\n","\n","G.cuda()\n","D.cuda()\n","\n","\n","# Binary Cross Entropy loss\n","BCE_loss = nn.BCELoss()"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6EJ-Q_msINIX"},"source":["### Define which optimizer we will use for the optimization of our neural network"]},{"cell_type":"code","metadata":{"id":"4xt2rB8LIKVg","executionInfo":{"status":"ok","timestamp":1621318869757,"user_tz":-480,"elapsed":609,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}}},"source":["# Adam optimizer\n","G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n","D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWbPWSR6IfS4"},"source":["### Start to training and save the reconstructed images"]},{"cell_type":"code","metadata":{"id":"iNgiGTEpTWHl","colab":{"base_uri":"https://localhost:8080/","height":432},"executionInfo":{"status":"error","timestamp":1621318871570,"user_tz":-480,"elapsed":976,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}},"outputId":"510aec3f-2691-4e40-9054-73e5b0879a53"},"source":["# results save folder\n","root = 'cDCGAN_results/'\n","model = 'cDCGAN_'\n","if not os.path.isdir(root):\n","    os.mkdir(root)\n","if not os.path.isdir(root + 'Fixed_results'):\n","    os.mkdir(root + 'Fixed_results')\n","\n","train_hist = {}\n","train_hist['D_losses'] = []\n","train_hist['G_losses'] = []\n","train_hist['per_epoch_ptimes'] = []\n","train_hist['total_ptime'] = []\n","\n","# label preprocess\n","onehot = torch.zeros(10, 10)\n","onehot = onehot.scatter_(1, torch.LongTensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).view(10,1), 1).view(10, 10, 1, 1)\n","fill = torch.zeros([10, 10, img_size, img_size])\n","for i in range(10):\n","    fill[i, i, :, :] = 1\n","\n","print('training start!')\n","start_time = time.time()\n","for epoch in range(train_epoch):\n","    D_losses = []\n","    G_losses = []\n","\n","    epoch_start_time = time.time()\n","    y_real_ = torch.ones(batch_size)\n","    y_fake_ = torch.zeros(batch_size)\n","    y_real_, y_fake_ = Variable(y_real_.cuda()), Variable(y_fake_.cuda())\n","    for x_, y_ in train_loader:\n","        # train discriminator D\n","        D.zero_grad()\n","\n","        mini_batch = x_.size()[0]\n","\n","        if mini_batch != batch_size:\n","            y_real_ = torch.ones(mini_batch)\n","            y_fake_ = torch.zeros(mini_batch)\n","            y_real_, y_fake_ = Variable(y_real_.cuda()), Variable(y_fake_.cuda())\n","\n","        y_fill_ = fill[y_]\n","        y_fill_ = fill[y_]\n","        x_, y_fill_ = Variable(x_.cuda()), Variable(y_fill_.cuda())\n","\n","        D_result = D(x_, y_fill_).squeeze()\n","        D_real_loss = BCE_loss(D_result, y_real_)\n","\n","        z_ = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)\n","        y_ = (torch.rand(mini_batch, 1) * 10).type(torch.LongTensor).squeeze()\n","        y_label_ = onehot[y_]\n","        y_fill_ = fill[y_]\n","        z_, y_label_, y_fill_ = Variable(z_.cuda()), Variable(y_label_.cuda()), Variable(y_fill_.cuda())\n","\n","        G_result = G(z_, y_label_)\n","        D_result = D(G_result, y_fill_).squeeze()\n","\n","        D_fake_loss = BCE_loss(D_result, y_fake_)\n","        D_fake_score = D_result.data.mean()\n","\n","        D_train_loss = D_real_loss + D_fake_loss\n","\n","        D_train_loss.backward()\n","        D_optimizer.step()\n","\n","        D_losses.append(D_train_loss.data)\n","\n","        # train generator G\n","        G.zero_grad()\n","\n","        z_ = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)\n","        y_ = (torch.rand(mini_batch, 1) * 10).type(torch.LongTensor).squeeze()\n","        y_label_ = onehot[y_]\n","        y_fill_ = fill[y_]\n","        z_, y_label_, y_fill_ = Variable(z_.cuda()), Variable(y_label_.cuda()), Variable(y_fill_.cuda())\n","\n","        G_result = G(z_, y_label_)\n","        D_result = D(G_result, y_fill_).squeeze()\n","\n","        G_train_loss = BCE_loss(D_result, y_real_)\n","\n","        G_train_loss.backward()\n","        G_optimizer.step()\n","\n","        \n","        G_losses.append(G_train_loss.data)\n","        \n","\n","    epoch_end_time = time.time()\n","    per_epoch_ptime = epoch_end_time - epoch_start_time\n","\n","    print('[%d/%d] - ptime: %.2f, loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), train_epoch, per_epoch_ptime, torch.mean(torch.FloatTensor(D_losses)),\n","                                                              torch.mean(torch.FloatTensor(G_losses))))\n","    fixed_p = root + 'Fixed_results/' + model + str(epoch + 1) + '.png'\n","\n","    show_result((epoch+1), save=True, path=fixed_p)\n","    train_hist['D_losses'].append(torch.mean(torch.FloatTensor(D_losses)))\n","    train_hist['G_losses'].append(torch.mean(torch.FloatTensor(G_losses)))\n","    train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n","\n","end_time = time.time()\n","total_ptime = end_time - start_time\n","train_hist['total_ptime'].append(total_ptime)\n","\n","show_train_hist(train_hist, save=True, path=root + model + 'train_hist.png')\n","\n","images = []\n","\n","for e in range(train_epoch):\n","    img_name = root + 'Fixed_results/' + model + str(e + 1) + '.png'\n","    images.append(imageio.imread(img_name))\n","imageio.mimsave(root + model + 'generation_animation.gif', images, fps=5)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["training start!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-386dcb65877c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mD_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fill_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mD_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCE_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mz_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2753\u001b[0m         raise ValueError(\n\u001b[1;32m   2754\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m         )\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 5, 5])) is deprecated. Please ensure they have the same size."]}]},{"cell_type":"markdown","metadata":{"id":"aOxHlO_4IyKo"},"source":["# Define the noise and label to generate the result."]},{"cell_type":"code","metadata":{"id":"3q8D6BVgebQ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621317342812,"user_tz":-480,"elapsed":672,"user":{"displayName":"Jirayu Petchhan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiTvwwFp8p8aIUr1O1n_NL_6Ex3wW2Yje0AnCH7og=s64","userId":"15677881651496530626"}},"outputId":"8ef7a850-9722-4712-a7f5-3a5227a9cdab"},"source":["# fixed noise & label\n","fixed_z_2 = torch.randn(10, 100)\n","fixed_z_2 = fixed_z_2.view(-1, 100, 1, 1)\n","\n","one_hot = [[1,0,0,0,0,0,0,0,0,0],\n","           [0,1,0,0,0,0,0,0,0,0],\n","           [0,0,1,0,0,0,0,0,0,0],\n","           [0,0,0,1,0,0,0,0,0,0],\n","           [0,0,0,0,1,0,0,0,0,0],\n","           [0,0,0,0,0,1,0,0,0,0],\n","           [0,0,0,0,0,0,1,0,0,0],\n","           [0,0,0,0,0,0,0,1,0,0],\n","           [0,0,0,0,0,0,0,0,1,0],\n","           [0,0,0,0,0,0,0,0,0,1]]\n","\n","\n","one_hot_arr = np.array(one_hot)\n","\n","fixed_y_label_2 = torch.from_numpy(one_hot_arr)\n","\n","fixed_y_label_2 = fixed_y_label_2.view(-1, 10, 1, 1)\n","\n","fixed_y_label_2 = fixed_y_label_2.float()\n","fixed_z_2 = fixed_z_2.float()\n","\n","fixed_z_2, fixed_y_label_2 = Variable(fixed_z_2.cuda()), Variable(fixed_y_label_2.cuda())\n","\n","def show_result_2(save_name='test', show = False, save = False, isFix=False):\n","       \n","    G.eval()\n","\n","    with torch.no_grad():\n","        test_images = G(fixed_z_2, fixed_y_label_2)\n","\n","    G.train()\n","    \n","    pic = to_img(test_images.cpu().data)\n","    img_path= './cDCGAN_results/output_{}.png'.format(save_name)\n","    save_image(pic,img_path)\n","    \n","def to_img(x):\n","    x = 0.5 * (x + 1)\n","    x = x.clamp(0, 1)\n","    x = x.view(-1, 1, 32, 32)\n","    return x\n","\n","show_result_2()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"}]}]}