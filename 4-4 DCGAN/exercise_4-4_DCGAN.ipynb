{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Exercise 6 \n",
    "\n",
    "This exercise introduces a Deep Convolutional Generative Adversarial Network\n",
    "\n",
    "We first import our framework. Since we are already familiar with pytorch, we will use the torch library. This will make it easy for us since we can use functions and classes other coders have already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "if not os.path.exists('./gan_img'):\n",
    "    os.mkdir('./gan_img')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyper-parameter and load the training dataset\n",
    "\n",
    "hyperparameters we define in here\n",
    "\n",
    "- img_size\n",
    "- give your experiment a concise name\n",
    "- batch_size (how big is one batch. This splits our dataset into equal pieces that we will feed into our neural network)\n",
    "- train_epoch (How long will we train)\n",
    "- learning rate\n",
    "- dataset we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "train_epoch = 50\n",
    "batch_size = 128\n",
    "noise_size = 100\n",
    "lr = 2e-4\n",
    "experiment_name= 'TEST_noise'\n",
    "experiment_path= './gan_img/{}'.format(experiment_name)\n",
    "\n",
    "if not os.path.exists(experiment_path):\n",
    "    os.mkdir(experiment_path)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=img_transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the generator and discriminator\n",
    "\n",
    "In here we are defining some functions that we will use later. Functions are very useful and you should write your functions whenever your code benefits from it. You should always declare your functions first in your script.\n",
    "\n",
    "- normal_init (we will use this function to initialize our weights)\n",
    "- show_result (outputs the images to a .png image)\n",
    "- show the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()\n",
    "        \n",
    "fixed_z_ = torch.randn((8 * 8, noise_size)).view(-1, noise_size, 1, 1)    # fixed noise\n",
    "fixed_z_ = Variable(fixed_z_.cuda())\n",
    "\n",
    "def show_result(num_epoch, show = False, save = False, isFix=False):\n",
    "    z_ = torch.randn((8*8, noise_size)).view(-1, noise_size, 1, 1)\n",
    "    z_ = Variable(z_)\n",
    "    if torch.cuda.is_available():\n",
    "        z_ = z_.cuda()\n",
    "        \n",
    "    G.eval()\n",
    "    if isFix:\n",
    "        with torch.no_grad():\n",
    "            test_images = G(fixed_z_)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            test_images = G(z_)\n",
    "    G.train()\n",
    "    \n",
    "    pic = to_img(test_images.cpu().data)\n",
    "    img_path= './gan_img/{}/output_{}.png'.format(experiment_name,num_epoch)\n",
    "    save_image(pic,img_path)\n",
    "    \n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 32, 32)\n",
    "    return x\n",
    "\n",
    "def show_loss():\n",
    "    pass\n",
    "\n",
    "def time_convert(sec):\n",
    "    mins = sec // 60\n",
    "    sec = sec % 60\n",
    "    hours = mins // 60\n",
    "    mins = mins % 60\n",
    "    print(\"Time Lapsed = {0} hours | {1} minutes | {2} seconds\".format(int(hours),int(mins),sec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our Generator structure as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, input_size = 100, d=64):\n",
    "        super(generator, self).__init__()\n",
    "        self.deconv1 = nn.ConvTranspose2d(input_size, d*4, 4, 1, 0)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d, 1, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.deconv1_bn(self.deconv1(input)))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.tanh(self.deconv4(x))\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the discriminator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=64):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(d)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, 1, 4, 1, 0)\n",
    "        \n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.leaky_relu(self.conv1_bn(self.conv1(input)), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.sigmoid(self.conv4(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of our generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################  Generator  ##################################\n",
      " generator(\n",
      "  (deconv1): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (deconv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv2): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv4): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      ") \n",
      "######################################################################################\n",
      "\n",
      "\n",
      "##############################  Discriminator  ########################################\n",
      " discriminator(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      ") \n",
      "######################################################################################\n"
     ]
    }
   ],
   "source": [
    "G = generator(input_size = noise_size)\n",
    "D = discriminator()\n",
    "\n",
    "G.weight_init(mean=0.0, std=0.02)\n",
    "D.weight_init(mean=0.0, std=0.02)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "\n",
    "print('###############################  Generator  ##################################\\n',\n",
    "      G,\n",
    "      '\\n######################################################################################\\n\\n')\n",
    "print('##############################  Discriminator  ########################################\\n',\n",
    "      D,\n",
    "      '\\n######################################################################################')\n",
    "\n",
    "BCE_loss = nn.BCELoss() \n",
    "#BCE_loss= nn.KLDivLoss(reduction='batchmean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define which optimizer we will use for the optimization of our neural network\n",
    "You can choose form the following\n",
    "\n",
    "- AdaGrad\n",
    "- SGD with and without momentum\n",
    "- Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_optimizer = torch.optim.Adagrad(D.parameters(), lr=lr)\n",
    "# G_optimizer = torch.optim.Adagrad(G.parameters(), lr=lr)\n",
    "\n",
    "# D_optimizer = torch.optim.SGD(D.parameters(), lr=lr, momentum=0.9)\n",
    "# G_optimizer = torch.optim.SGD(G.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "D_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "G_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to training and save the reconstructed images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "D:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50]: Loss_D: 0.364, Loss_G: 3.443\n",
      "[2/50]: Loss_D: 0.464, Loss_G: 2.661\n",
      "[3/50]: Loss_D: 0.584, Loss_G: 2.118\n",
      "[4/50]: Loss_D: 0.581, Loss_G: 2.049\n",
      "[5/50]: Loss_D: 0.520, Loss_G: 2.245\n",
      "[6/50]: Loss_D: 0.493, Loss_G: 2.432\n",
      "[7/50]: Loss_D: 0.419, Loss_G: 2.683\n",
      "[8/50]: Loss_D: 0.402, Loss_G: 2.753\n"
     ]
    }
   ],
   "source": [
    "starttime=time.time()\n",
    "for epoch in range(train_epoch):\n",
    "    \n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    for i, (x_, _ )in enumerate(dataloader, 0):\n",
    "        # train discriminator D\n",
    "        D.zero_grad()\n",
    "        mini_batch = x_.size()[0]\n",
    "\n",
    "        y_real_ = torch.ones(mini_batch)\n",
    "        y_fake_ = torch.zeros(mini_batch)\n",
    "        \n",
    "        x_, y_real_, y_fake_ = Variable(x_), Variable(y_real_), Variable(y_fake_)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            x_ = x_.cuda()\n",
    "            y_real_ = y_real_.cuda()\n",
    "            y_fake_ = y_fake_.cuda()\n",
    "\n",
    "\n",
    "        D_result = D(x_).squeeze()\n",
    "        D_real_loss = BCE_loss(D_result, y_real_)\n",
    "        D_real_score = D_result\n",
    "\n",
    "        z_ = torch.randn((mini_batch, noise_size)).view(-1, noise_size, 1, 1) #-1 in .view() means that the dimension is inferred from other dimensions\n",
    "        z_ = Variable(z_)\n",
    "        if torch.cuda.is_available():\n",
    "            z_ = z_.cuda()\n",
    "        G_result = G(z_)\n",
    "        \n",
    "        D_result = D(G_result).squeeze()\n",
    "        D_fake_loss = BCE_loss(D_result, y_fake_)\n",
    "        D_fake_score = D_result.data.mean()\n",
    "\n",
    "        D_train_loss = D_real_loss + D_fake_loss\n",
    "\n",
    "        D_train_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        D_losses.append(D_train_loss.data)\n",
    "\n",
    "        # train generator G\n",
    "\n",
    "        G.zero_grad()\n",
    "        \n",
    "        z_ = torch.randn((mini_batch, noise_size)).view(-1, noise_size, 1, 1)\n",
    "\n",
    "\n",
    "        z_ = Variable(z_)\n",
    "        if torch.cuda.is_available():\n",
    "            z_ = z_.cuda()\n",
    "\n",
    "        G_result = G(z_)\n",
    "        D_result = D(G_result).squeeze()\n",
    "        G_train_loss = BCE_loss(D_result, y_real_)\n",
    "        G_train_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        G_losses.append(G_train_loss.data)\n",
    "\n",
    "\n",
    "    print('[%d/%d]: Loss_D: %.3f, Loss_G: %.3f' % (\n",
    "        (epoch+1), train_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
    "    if epoch % 1 == 0:\n",
    "        save_path = './gan_img/{}/output_{}.png'.format(experiment_name,epoch)\n",
    "        show_result((epoch+1), save=True, isFix=True)\n",
    "        \n",
    "endtime=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us have a look at the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "figurename=experiment_path +'/'+'losscurve.png'\n",
    "plt.savefig(figurename,format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us take a look at the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_convert(round(endtime-starttime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
